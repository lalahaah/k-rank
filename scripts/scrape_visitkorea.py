"""
ëŒ€í•œë¯¼êµ­ êµ¬ì„êµ¬ì„ ì‚¬ì´íŠ¸ì—ì„œ ì¸ê¸°ìˆœ ì—¬í–‰ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ìŠ¤í¬ë˜í•‘í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸  
Playwrightë¥¼ ì‚¬ìš©í•˜ì—¬ JavaScript ë Œë”ë§ ì™„ì „ ëŒ€ê¸°
"""
import asyncio
from playwright.async_api import async_playwright
import json
import re


async def scrape_popular_places(limit=30):
    """
    ëŒ€í•œë¯¼êµ­ êµ¬ì„êµ¬ì„ ì‚¬ì´íŠ¸ì—ì„œ ì¸ê¸°ìˆœ ì—¬í–‰ì§€ ë¦¬ìŠ¤íŠ¸ ìŠ¤í¬ë˜í•‘
    
    Args:
        limit (int): ìˆ˜ì§‘í•  ì¥ì†Œ ê°œìˆ˜
    
    Returns:
        list: ì¸ê¸° ì—¬í–‰ì§€ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    print(f"ğŸŒ ëŒ€í•œë¯¼êµ­ êµ¬ì„êµ¬ì„ ì‚¬ì´íŠ¸ì—ì„œ ìƒìœ„ {limit}ê°œ ì¸ê¸° ì—¬í–‰ì§€ë¥¼ ìŠ¤í¬ë˜í•‘í•©ë‹ˆë‹¤...")
    
    async with async_playwright() as p:
        # Chromium ë¸Œë¼ìš°ì € ì‹¤í–‰
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        
        places = []
        
        try:
            # í˜ì´ì§€ ì ‘ì† - networkidle ëŒ€ê¸°
            print("ğŸ“ í˜ì´ì§€ ë¡œë”© ì¤‘...")
            await page.goto('https://korean.visitkorea.or.kr/list/travelinfo.do?service=ms', 
                          wait_until='networkidle',
                          timeout=60000)
            
            # ì¶”ê°€ ëŒ€ê¸°
            await asyncio.sleep(3)
            
            # ì¸ê¸°ìˆœ ì •ë ¬ ì„¤ì • - URLì— srchType=3 íŒŒë¼ë¯¸í„° ì¶”ê°€í•˜ì—¬ ì¬ë¡œë“œ
            print("ğŸ”¥ ì¸ê¸°ìˆœìœ¼ë¡œ í˜ì´ì§€ ì¬ë¡œë“œ...")
            await page.goto('https://korean.visitkorea.or.kr/list/travelinfo.do?service=ms&srchType=3',
                          wait_until='networkidle',
                          timeout=60000)
            
            await asyncio.sleep(3)
            
            # í˜ì´ì§€ HTML ì €ì¥ for debugging
            html_content = await page.content()
            print(f"  â„¹ï¸  í˜ì´ì§€ HTML ê¸¸ì´: {len(html_content)} ë¬¸ì")
            
            # ë¦¬ìŠ¤íŠ¸ í•­ëª© ì°¾ê¸° ì‹œë„
            items = await page.locator('ul.list_thumType li').all()
            
            if not items:
                print("  âš ï¸  'ul.list_thumType li' ì…€ë ‰í„°ë¡œ í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                # ëŒ€ì•ˆ ì…€ë ‰í„° ì‹œë„
                items = await page.locator('li').all()
                print(f"  â„¹ï¸  ì „ì²´ li íƒœê·¸: {len(items)}ê°œ")
                # strong íƒœê·¸ê°€ ìˆëŠ” lië§Œ í•„í„°ë§
                filtered_items = []
                for item in items:
                    strong = await item.query_selector('strong')
                    if strong:
                        filtered_items.append(item)
                items = filtered_items
                print(f"  â„¹ï¸  strong íƒœê·¸ê°€ ìˆëŠ” li: {len(items)}ê°œ")
            
            print(f"ğŸ“„ ì´ {len(items)}ê°œ í•­ëª© ë°œê²¬")
            
            for item in items:
                if len(places) >= limit:
                    break
                
                try:
                    # ì œëª©
                    title_elem = await item.query_selector('strong.tit, strong')
                    name = await title_elem.inner_text() if title_elem else ""
                    name = name.strip()
                    
                    if not name:
                        continue
                    
                    # ì§€ì—­
                    p_elems = await item.query_selector_all('p')
                    location = ""
                    if len(p_elems) > 0:
                        location_text = await p_elems[0].inner_text()
                        location = location_text.strip()
                    
                    # ì„¤ëª…
                    desc_elem = await item.query_selector('p.phrase')
                    description = ""
                    if desc_elem:
                        desc_text = await desc_elem.inner_text()
                        description = desc_text.strip()
                    elif len(p_elems) > 1:
                        desc_text = await p_elems[1].inner_text()
                        description = desc_text.strip()
                    
                    # íƒœê·¸
                    tags = []
                    tag_container = await item.query_selector('p.tag')
                    if tag_container:
                        tag_elems = await tag_container.query_selector_all('span')
                        for tag_elem in tag_elems:
                            tag_text = await tag_elem.inner_text()
                            if tag_text:
                                tags.append(tag_text.strip())
                    
                    # ì´ë¯¸ì§€
                    img_elem = await item.query_selector('img')
                    image_url = ""
                    if img_elem:
                        image_url = await img_elem.get_attribute('src')
                        if image_url and not image_url.startswith('http'):
                            image_url = f"https://korean.visitkorea.or.kr{image_url}"
                    
                    # Content ID
                    content_id = ""
                    link_elem = await item.query_selector('a[onclick]')
                    if link_elem:
                        onclick = await link_elem.get_attribute('onclick')
                        match = re.search(r"goDetail\('([^']+)'", onclick)
                        if match:
                            content_id = match.group(1)
                    
                    # ìœ íš¨í•œ ë°ì´í„°ë§Œ ì¶”ê°€
                    if name and location:
                        place_data = {
                            'name': name,
                            'location': location,
                            'description': description,
                            'tags': tags,
                            'image_url': image_url,
                            'content_id': content_id
                        }
                        places.append(place_data)
                        print(f"  âœ… {len(places)}. {name} ({location})")
                
                except Exception as e:
                    print(f"  âš ï¸  í•­ëª© íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue
            
            # ë” ë§ì€ í•­ëª©ì´ í•„ìš”í•˜ë©´ í˜ì´ì§€ 2ë¡œ ì´ë™
            if len(places) < limit:
                print(f"\nğŸ“„ ì¶”ê°€ ë°ì´í„° í•„ìš” - í˜ì´ì§€ 2ë¡œ ì´ë™...")
                try:
                    # í˜ì´ì§€ 2 URLë¡œ ì§ì ‘ ì´ë™
                    await page.goto('https://korean.visitkorea.or.kr/list/travelinfo.do?service=ms&srchType=3&cPage=2',
                                  wait_until='networkidle',
                                  timeout=60000)
                    await asyncio.sleep(3)
                    
                    second_page_items = await page.locator('ul.list_thumType li').all()
                    if not second_page_items:
                        # ëŒ€ì•ˆ ì…€ë ‰í„°
                        all_lis = await page.locator('li').all()
                        second_page_items = []
                        for item in all_lis:
                            strong = await item.query_selector('strong')
                            if strong:
                                second_page_items.append(item)
                    
                    print(f"  â„¹ï¸  í˜ì´ì§€ 2ì—ì„œ {len(second_page_items)}ê°œ í•­ëª© ë°œê²¬")
                    
                    for item in second_page_items:
                        if len(places) >= limit:
                            break
                        
                        try:
                            title_elem = await item.query_selector('strong.tit, strong')
                            name = await title_elem.inner_text() if title_elem else ""
                            name = name.strip()
                            
                            if not name:
                                continue
                            
                            p_elems = await item.query_selector_all('p')
                            location = ""
                            if len(p_elems) > 0:
                                location = (await p_elems[0].inner_text()).strip()
                            
                            desc_elem = await item.query_selector('p.phrase')
                            description = ""
                            if desc_elem:
                                description = (await desc_elem.inner_text()).strip()
                            elif len(p_elems) > 1:
                                description = (await p_elems[1].inner_text()).strip()
                            
                            tags = []
                            tag_container = await item.query_selector('p.tag')
                            if tag_container:
                                tag_elems = await tag_container.query_selector_all('span')
                                for tag_elem in tag_elems:
                                    tag_text = await tag_elem.inner_text()
                                    if tag_text:
                                        tags.append(tag_text.strip())
                            
                            img_elem = await item.query_selector('img')
                            image_url = ""
                            if img_elem:
                                image_url = await img_elem.get_attribute('src')
                                if image_url and not image_url.startswith('http'):
                                    image_url = f"https://korean.visitkorea.or.kr{image_url}"
                            
                            content_id = ""
                            link_elem = await item.query_selector('a[onclick]')
                            if link_elem:
                                onclick = await link_elem.get_attribute('onclick')
                                match = re.search(r"goDetail\('([^']+)'", onclick)
                                if match:
                                    content_id = match.group(1)
                            
                            if name and location:
                                place_data = {
                                    'name': name,
                                    'location': location,
                                    'description': description,
                                    'tags': tags,
                                    'image_url': image_url,
                                    'content_id': content_id
                                }
                                places.append(place_data)
                                print(f"  âœ… {len(places)}. {name} ({location})")
                        
                        except Exception as e:
                            print(f"  âš ï¸  í•­ëª© íŒŒì‹± ì˜¤ë¥˜: {e}")
                            continue
                
                except Exception as e:
                    print(f"âš ï¸  í˜ì´ì§€ 2 ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        except Exception as e:
            print(f"âŒ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
        
        finally:
            await browser.close()
    
    print(f"\nâœ… ì´ {len(places)}ê°œ ì¥ì†Œ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ!")
    return places


async def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    places = await scrape_popular_places(limit=30)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*80)
    print("ğŸ“‹ ìŠ¤í¬ë˜í•‘ ê²°ê³¼:")
    print("="*80)
    for i, place in enumerate(places, 1):
        print(f"\n{i}. {place['name']}")
        print(f"   ì§€ì—­: {place['location']}")
        if place['description']:
            desc_preview = place['description'][:50] + "..." if len(place['description']) > 50 else place['description']
            print(f"   ì„¤ëª…: {desc_preview}")
        print(f"   íƒœê·¸: {', '.join(place['tags'])}")
        print(f"   Content ID: {place['content_id']}")
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    with open('popular_places.json', 'w', encoding='utf-8') as f:
        json.dump(places, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ê²°ê³¼ê°€ 'popular_places.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    asyncio.run(main())
