#!/usr/bin/env python3
"""
K-Rank Food Scraper (Google Places API New)
Google Places API (New)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œìš¸ì˜ íŠ¸ë Œë”© ë ˆìŠ¤í† ë‘ì„ ìˆ˜ì§‘í•˜ê³  Firebaseì— ì €ì¥í•©ë‹ˆë‹¤.
"""

import os
import sys
import math
import json
import asyncio
from datetime import datetime, timezone, timedelta
from typing import List, Dict, Any
from dotenv import load_dotenv

import requests
import firebase_admin
from firebase_admin import credentials, firestore
import google.generativeai as genai

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ê°œë°œ ëª¨ë“œ ì„¤ì •
DEV_MODE = os.getenv('DEV_MODE', 'false').lower() == 'true'
WRITE_TO_FIRESTORE = os.getenv('WRITE_TO_FIRESTORE', 'false').lower() == 'true'
DEV_LIMIT = int(os.getenv('DEV_LIMIT', '5'))

# ì„œìš¸ í•«í”Œë ˆì´ìŠ¤ ì¢Œí‘œ
HOT_AREAS = [
    {"name": "Gangnam", "location": {"latitude": 37.4979, "longitude": 127.0276}, "displayName": "Gangnam, Seoul"},
    {"name": "Seongsu", "location": {"latitude": 37.5444, "longitude": 127.0557}, "displayName": "Seongsu, Seoul"},
    {"name": "Hannam", "location": {"latitude": 37.5340, "longitude": 127.0030}, "displayName": "Hannam, Seoul"},
    {"name": "Hongdae", "location": {"latitude": 37.5563, "longitude": 126.9240}, "displayName": "Hongdae, Seoul"},
    {"name": "Dosan", "location": {"latitude": 37.5220, "longitude": 127.0390}, "displayName": "Dosan, Seoul"},
    {"name": "Itaewon", "location": {"latitude": 37.5345, "longitude": 126.9945}, "displayName": "Itaewon, Seoul"},
]

CACHE_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'product_cache.json')

def load_cache() -> Dict[str, Any]:
    """ë¡œì»¬ ìºì‹œ íŒŒì¼ ë¡œë“œ"""
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âš ï¸  ìºì‹œ ë¡œë“œ ì˜¤ë¥˜: {e}")
    return {}

def save_cache(cache: Dict[str, Any]):
    """ë¡œì»¬ ìºì‹œ íŒŒì¼ ì €ì¥"""
    try:
        with open(CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(cache, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âš ï¸  ìºì‹œ ì €ì¥ ì˜¤ë¥˜: {e}")

def initialize_firebase():
    """Firebase Admin SDK ì´ˆê¸°í™”"""
    if not firebase_admin._apps:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(script_dir)
        key_path = os.path.join(project_root, 'serviceAccountKey.json')
        
        cred = credentials.Certificate(key_path)
        firebase_admin.initialize_app(cred)
    return firestore.client()

def initialize_gemini():
    """Gemini API ì´ˆê¸°í™”"""
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        raise ValueError("GEMINI_API_KEY not found in environment variables")
    genai.configure(api_key=api_key)
    return genai.GenerativeModel('models/gemini-2.0-flash')

def calculate_hype_score(rating: float, user_ratings_total: int, recency_boost: float = 1.0) -> int:
    """Hype Score ê³„ì‚°"""
    if user_ratings_total == 0 or rating == 0:
        return 0
    
    rating_factor = rating / 5.0
    review_factor = min(10, math.log10(user_ratings_total + 1) * 2)
    score = int(rating_factor * review_factor * 10 * recency_boost)
    
    return min(100, score)

def get_status(hype_score: int) -> str:
    """Hype Score ê¸°ë°˜ ìƒíƒœ ì¶”ì •"""
    if hype_score >= 95:
        return "Hard to Book"
    elif hype_score >= 85:
        return "Queueing"
    else:
        return "Available"

def search_nearby_places(api_key: str, location: Dict, radius: int = 1000) -> List[Dict]:
    """Places API (New) - Nearby Search"""
    url = "https://places.googleapis.com/v1/places:searchNearby"
    
    headers = {
        "Content-Type": "application/json",
        "X-Goog-Api-Key": api_key,
        "X-Goog-FieldMask": "places.id,places.displayName,places.rating,places.userRatingCount,places.types,places.formattedAddress,places.location,places.photos,places.internationalPhoneNumber,places.priceLevel,places.googleMapsUri"
    }
    
    data = {
        "includedTypes": ["restaurant"],
        "maxResultCount": 20,
        "locationRestriction": {
            "circle": {
                "center": location,
                "radius": radius
            }
        }
    }
    
    response = requests.post(url, headers=headers, json=data)
    
    if response.status_code == 200:
        result = response.json()
        return result.get("places", [])
    else:
        print(f"   âŒ API ì˜¤ë¥˜: {response.status_code}")
        return []

def scrape_google_places_new(api_key: str, max_per_area: int = 3) -> List[Dict[str, Any]]:
    """Google Places API (New)ë¡œ íŠ¸ë Œë”© ë ˆìŠ¤í† ë‘ ìˆ˜ì§‘"""
    print("ğŸ½ï¸  Google Places API (New)ë¡œ ë ˆìŠ¤í† ë‘ ìˆ˜ì§‘ ì‹œì‘...")
    
    all_restaurants = []
    seen_place_ids = set()
    
    for area in HOT_AREAS:
        print(f"\nğŸ“ {area['name']} ì§€ì—­ ê²€ìƒ‰ ì¤‘...")
        
        try:
            places = search_nearby_places(api_key, area['location'])
            print(f"   {len(places)}ê°œ ì¥ì†Œ ë°œê²¬")
            
            # í‰ì ê³¼ ë¦¬ë·° ìˆ˜ë¡œ ì •ë ¬
            places.sort(
                key=lambda p: (p.get('rating', 0) * math.log10(p.get('userRatingCount', 0) + 1)),
                reverse=True
            )
            
            count = 0
            for place in places[:max_per_area * 3]: # ì—¬ìœ  ìˆê²Œ ìˆ˜ì§‘
                place_id = place.get('id', '')
                
                if place_id in seen_place_ids:
                    continue
                
                seen_place_ids.add(place_id)
                
                # ê¸°ë³¸ ì •ë³´
                name = place.get('displayName', {}).get('text', 'Unknown')
                rating = place.get('rating', 0)
                reviews = place.get('userRatingCount', 0)
                
                # ë¦¬ë·°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ìŠ¤í‚µ (ê²€ì¦ ê°•í™”)
                if reviews < 50:
                    continue
                
                # Hype Score ê³„ì‚°
                hype_score = calculate_hype_score(rating, reviews)
                
                # ì´ë¯¸ì§€ URL
                photos = place.get('photos', [])
                if photos:
                    photo_name = photos[0].get('name', '')
                    image_url = f"https://places.googleapis.com/v1/{photo_name}/media?maxWidthPx=1920&maxHeightPx=1080&key={api_key}"
                else:
                    image_url = "https://images.unsplash.com/photo-1517248135467-4c7edcad34c4?q=80&w=1920&h=1080&auto=format&fit=crop"
                
                # ì¹´í…Œê³ ë¦¬ ì¶”ë¡ 
                types = place.get('types', [])
                if 'cafe' in types or 'bakery' in types:
                    category = 'Bakery / Cafe'
                elif 'bar' in types:
                    category = 'Bar'
                else:
                    category = 'Restaurant'
                
                price_level_map = {
                    'PRICE_LEVEL_FREE': 'â‚©',
                    'PRICE_LEVEL_INEXPENSIVE': 'â‚©',
                    'PRICE_LEVEL_MODERATE': 'â‚©â‚©',
                    'PRICE_LEVEL_EXPENSIVE': 'â‚©â‚©â‚©',
                    'PRICE_LEVEL_VERY_EXPENSIVE': 'â‚©â‚©â‚©â‚©'
                }
                price_range = price_level_map.get(place.get('priceLevel', 'PRICE_LEVEL_MODERATE'), 'â‚©â‚©')
                
                location_data = place.get('location', {})
                latitude = location_data.get('latitude', 0)
                longitude = location_data.get('longitude', 0)
                
                restaurant = {
                    'name': name,
                    'nameKo': name,
                    'location': area['displayName'],
                    'category': category,
                    'imageUrl': image_url,
                    'rating': rating,
                    'reviews': reviews,
                    'hypeScore': hype_score,
                    'status': get_status(hype_score),
                    'latitude': latitude,
                    'longitude': longitude,
                    'aiInsight': {
                        'summary': '',
                        'tips': '',
                        'tags': []
                    },
                    'details': {
                        'address': place.get('formattedAddress', ''),
                        'phone': place.get('internationalPhoneNumber', ''),
                        'hours': '',
                        'priceRange': price_range,
                        'mustTry': []
                    },
                    'links': {
                        'reservation': '',
                        'map': place.get('googleMapsUri', '')
                    },
                    'trend': 0
                }
                
                all_restaurants.append(restaurant)
                count += 1
                print(f"   âœ“ {name} (Rating: {rating}, Reviews: {reviews}, Hype: {hype_score})")
                
                if count >= max_per_area:
                    break
                    
        except Exception as e:
            print(f"   âŒ {area['name']} ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            continue
    
    # Hype Scoreë¡œ ì •ë ¬ í›„ Top 30
    all_restaurants.sort(key=lambda x: x['hypeScore'], reverse=True)
    limit = 30
    if DEV_MODE:
        limit = DEV_LIMIT * 5 # ì§€ì—­ë³„ ìˆ˜ì§‘ëŸ‰ì„ ê³ ë ¤í•˜ì—¬ ì—¬ìœ  ìˆê²Œ
        
    top_restaurants = all_restaurants[:limit]
    
    # ìˆœìœ„ ë¶€ì—¬
    for idx, restaurant in enumerate(top_restaurants, 1):
        restaurant['rank'] = idx
    
    print(f"\nâœ… ì´ {len(top_restaurants)}ê°œ ë ˆìŠ¤í† ë‘ ì„ ì • ì™„ë£Œ")
    
    return top_restaurants

async def analyze_restaurants_batch(model: genai.GenerativeModel, restaurants: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Gemini AIë¡œ ë ˆìŠ¤í† ë‘ ì´ë¦„ ë²ˆì—­ ë° ì¸ì‚¬ì´íŠ¸ í†µí•© ìƒì„±"""
    print("\nğŸŒ Gemini AIë¡œ ì´ë¦„ ë²ˆì—­ ë° ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ (Batch Processing)...")
    
    cache = load_cache()
    to_process = []
    
    for r in restaurants:
        cache_key = f"restaurant_{r['name']}"
        if cache_key in cache:
            cached_data = cache[cache_key]
            r['nameKo'] = cached_data.get('nameKo', r['name'])
            r['aiInsight'] = cached_data.get('aiInsight', r['aiInsight'])
            r['details']['mustTry'] = cached_data.get('mustTry', [])
            print(f"  âš¡ ìºì‹œ ì‚¬ìš©")
        else:
            to_process.append(r)
            
    if not to_process:
        print("âœ… ëª¨ë“  ë ˆìŠ¤í† ë‘ì´ ìºì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        return restaurants

    print(f"  ğŸ¤– {len(to_process)}ê°œ ë ˆìŠ¤í† ë‘ AI ë¶„ì„ ìš”ì²­ ì¤‘...")
    
    # 10ê°œì”© ë°°ì¹˜ ì²˜ë¦¬
    batch_size = 10
    for i in range(0, len(to_process), batch_size):
        batch = to_process[i:i+batch_size]
        
        info_list = [
            f"Rank {r['rank']}: {r['name']} ({r['category']} in {r['location']})"
            for r in batch
        ]
        
        prompt = f"""
Analyze the following restaurants in Seoul and provide translations and insights.

RESTAURANTS:
{chr(10).join(info_list)}

FOR EACH RESTAURANT, PROVIDE:
1. nameKo: The common Korean name of the restaurant.
2. summary: A 1-2 sentence enticing description in English.
3. tips: Practical visiting tip in English.
4. tags: 2-3 short hashtags (e.g., ["Viral", "Aesthetic"]).
5. mustTry: 2-3 recommended menu items in English.

RESPONSE FORMAT (JSON):
{{
  "results": [
    {{
      "rank": 1,
      "nameKo": "í•œêµ­ì–´ ì´ë¦„",
      "summary": "...",
      "tips": "...",
      "tags": ["...", "..."],
      "mustTry": ["...", "..."]
    }},
    ...
  ]
}}

JSON ONLY.
        """
        
        try:
            response = await model.generate_content_async(prompt)
            result_text = response.text.strip()
            
            # JSON í´ë Œì§•
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0].strip()
            
            data = json.loads(result_text)
            results = data.get('results', [])
            
            for res in results:
                rank = res.get('rank')
                for r in batch:
                    if r['rank'] == rank:
                        r['nameKo'] = res.get('nameKo', r['name'])
                        r['aiInsight'] = {
                            'summary': res.get('summary', ''),
                            'tips': res.get('tips', ''),
                            'tags': res.get('tags', [])
                        }
                        r['details']['mustTry'] = res.get('mustTry', [])
                        
                        # ìºì‹œ ì €ì¥
                        cache_key = f"restaurant_{r['name']}"
                        cache[cache_key] = {
                            'nameKo': r['nameKo'],
                            'aiInsight': r['aiInsight'],
                            'mustTry': r['details']['mustTry'],
                            'updatedAt': datetime.now(timezone.utc).isoformat()
                        }
                        break
            
            print(f"  âœ… ë°°ì¹˜ {i//batch_size + 1} ì™„ë£Œ")
            save_cache(cache)
            
        except Exception as e:
            print(f"  âŒ ë°°ì¹˜ {i//batch_size + 1} ì˜¤ë¥˜: {e}")
            # í´ë°±
            for r in batch:
                r['nameKo'] = r['name']
                r['aiInsight'] = {
                    'summary': f"Popular {r['category'].lower()} in {r['location']}.",
                    'tips': "Check maps for busy hours.",
                    'tags': ["Seoul", r['category']]
                }

    return restaurants

async def calculate_restaurant_trends(db: firestore.client, current_items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """ë ˆìŠ¤í† ë‘ ìˆœìœ„ ë³€ë™(Trend) ê³„ì‚°"""
    print("\nğŸ“ˆ ìˆœìœ„ ë³€ë™ ê³„ì‚° ì¤‘...")
    
    # ì–´ì œ ë‚ ì§œ í™•ì¸
    yesterday = (datetime.now(timezone.utc) - timedelta(days=1)).strftime('%Y-%m-%d')
    doc_id = f"{yesterday}_restaurants"
    
    try:
        prev_doc = db.collection('daily_rankings').document(doc_id).get()
        if not prev_doc.exists:
            print(f"  â„¹ï¸ ì–´ì œ ë°ì´í„°({yesterday})ê°€ ì—†ì–´ ë³€ë™ì„ 0ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
            return current_items
            
        prev_data = prev_doc.to_dict()
        prev_items = prev_data.get('items', [])
        
        # ì´ì „ ìˆœìœ„ ë§¤í•‘
        prev_rank_map = {item['name']: item['rank'] for item in prev_items}
        
        for item in current_items:
            prev_rank = prev_rank_map.get(item['name'])
            if prev_rank:
                item['trend'] = prev_rank - item['rank']
            else:
                item['trend'] = 0 # ì‹ ê·œ ì§„ì…ì€ 0ìœ¼ë¡œ í‘œì‹œ (ë˜ëŠ” ë‹¤ë¥¸ ë¡œì§)
                
        print("  âœ… ë³€ë™ ê³„ì‚° ì™„ë£Œ")
    except Exception as e:
        print(f"  âš ï¸  ë³€ë™ ê³„ì‚° ì˜¤ë¥˜: {e}")
        
    return current_items

def save_to_firebase(db, restaurants: List[Dict[str, Any]]):
    """Firebaseì— ë ˆìŠ¤í† ë‘ ë°ì´í„° ì €ì¥"""
    print("\nğŸ’¾ Firebaseì— ì €ì¥ ì¤‘...")
    
    today = datetime.now(timezone.utc).strftime('%Y-%m-%d')
    doc_id = f"{today}_restaurants"
    
    data = {
        'category': 'restaurants',
        'date': today,
        'lastUpdated': datetime.now(timezone.utc),
        'items': restaurants
    }
    
    if DEV_MODE and not WRITE_TO_FIRESTORE:
        print(f"ğŸ§ª  [DEV_MODE] Firebase ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        print(f"  ğŸ“Š {len(data['items'])}ê°œ ë ˆìŠ¤í† ë‘ ì¤€ë¹„ë¨")
        return

    doc_ref = db.collection('daily_rankings').document(doc_id)
    doc_ref.set(data)
    
    print(f"âœ… {len(restaurants)}ê°œ ë ˆìŠ¤í† ë‘ ì €ì¥ ì™„ë£Œ (ë¬¸ì„œ ID: {doc_id})")

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("\n" + "=" * 60)
    print("ğŸœ K-Rank Food Scraper (Google Places API New)")
    print(f"MODE: {'DEVELOPMENT' if DEV_MODE else 'PRODUCTION'}")
    print("=" * 60)
    
    api_key = os.getenv('GOOGLE_PLACES_API_KEY') or os.getenv('GOOGLE_MAPS_API_KEY') or os.getenv('GEMINI_API_KEY')
    if not api_key:
        print("âŒ GOOGLE_PLACES_API_KEY, GOOGLE_MAPS_API_KEY ë˜ëŠ” GEMINI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    db = initialize_firebase()
    
    try:
        model = initialize_gemini()
    except Exception as e:
        print(f"âš ï¸  Gemini ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        model = None
    
    # 1. Google Placesì—ì„œ ë ˆìŠ¤í† ë‘ ìˆ˜ì§‘
    max_per_area = 2 if DEV_MODE else 7
    restaurants = scrape_google_places_new(api_key, max_per_area=max_per_area)
    
    if not restaurants:
        print("\nâŒ [CRITICAL] ìˆ˜ì§‘ëœ ë ˆìŠ¤í† ë‘ ë°ì´í„°ê°€ 0ê°œì…ë‹ˆë‹¤.")
        sys.exit(1)
    
    # 2. Gemini AI ë¶„ì„ (ë²ˆì—­ + ì¸ì‚¬ì´íŠ¸)
    if model:
        restaurants = await analyze_restaurants_batch(model, restaurants)
    
    # 3. íŠ¸ë Œë“œ ê³„ì‚°
    restaurants = await calculate_restaurant_trends(db, restaurants)
    
    # 4. Firebaseì— ì €ì¥
    save_to_firebase(db, restaurants)
    
    print("\nâœ… Food ìŠ¤í¬ë˜í¼ ì™„ë£Œ!")
    print(f"ì´ {len(restaurants)}ê°œ ë ˆìŠ¤í† ë‘ ì²˜ë¦¬ ì™„ë£Œ")

if __name__ == '__main__':
    asyncio.run(main())
