#!/usr/bin/env python3
"""
K-Rank Editorial Ranking Importer
ì‚¬ìš©ìê°€ ì œê³µí•œ ì—ë””í† ë¦¬ì–¼ ë¦¬í¬íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°ì´í„°ë¥¼ ê°€ê³µí•˜ê³  Firestoreì— ì €ì¥í•©ë‹ˆë‹¤.
"""

import asyncio
import os
import sys
import json
import random
import time
import re
import aiohttp
from datetime import datetime, timezone
from typing import List, Dict, Any

import requests
import firebase_admin
from firebase_admin import credentials, firestore
import google.generativeai as genai
from dotenv import load_dotenv

# ê¸°ì¡´ scraper ë¡œì§ ì¬ì‚¬ìš©ì„ ìœ„í•´ ê²½ë¡œ ì„¤ì •
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(script_dir)
env_path = os.path.join(project_root, '.env')
load_dotenv(env_path)

# scraper.pyì—ì„œ í•„ìš”í•œ í•¨ìˆ˜ë“¤ì„ ì„í¬íŠ¸í•˜ê¸° ìœ„í•´ sys.path ì¶”ê°€
sys.path.append(script_dir)
from scraper import (
    initialize_firebase, initialize_gemini, get_amazon_image,
    calculate_nik_index, BRAND_NAME_MAPPING, auto_romanize_korean,
    normalize_product_name, CATEGORY_MAPPING, save_cache, load_cache
)

# ì„¤ì •
DATA_FILE = os.path.join(script_dir, 'editorial_ranking_v2_4.json')
DEV_MODE = os.getenv('DEV_MODE', 'false').lower() == 'true'
WRITE_TO_FIRESTORE = os.getenv('WRITE_TO_FIRESTORE', 'true').lower() == 'true'
PREVIOUS_DATA_FILE = os.path.join(script_dir, 'editorial_ranking_v2_3.json')

def parse_brand_and_product(raw_name: str):
    """'ë¸Œëœë“œëª… ì œí’ˆëª… (ë¶€ê°€ì •ë³´)' í˜•ì‹ì—ì„œ ë¸Œëœë“œì™€ ì œí’ˆëª… ë¶„ë¦¬"""
    # ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ì œê±°
    clean_name = re.sub(r'\(.*?\)', '', raw_name).strip()
    
    # ê³µë°±ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì²« ë²ˆì§¸ ë‹¨ì–´ë¥¼ ë¸Œëœë“œë¡œ ì¶”ì • (í•œê¸€ ë¸Œëœë“œì˜ ì¼ë°˜ì ì¸ ì¼€ì´ìŠ¤)
    parts = clean_name.split(' ', 1)
    if len(parts) > 1:
        brand = parts[0]
        product = parts[1]
    else:
        brand = "Unknown"
        product = parts[0]
        
    return brand, product

async def check_url_valid(url: str) -> bool:
    """URLì´ ìœ íš¨í•œì§€(404ê°€ ì•„ë‹Œì§€) í™•ì¸"""
    if not url: return False
    # Unsplash ë° Amazon ë¯¸ë””ì–´ URLì€ ìœ íš¨í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼ (ì§ì ‘ ë„£ì€ ê³ í’ˆì§ˆ ì´ë¯¸ì§€)
    if "images.unsplash.com" in url or "m.media-amazon.com" in url: return True
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        async with aiohttp.ClientSession(headers=headers) as session:
            async with session.get(url, timeout=5) as response:
                return response.status == 200
    except:
        return False

def generate_default_tags(category_key: str, product_name: str) -> List[str]:
    """Gemini ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  êµ¬ì²´ì ì¸ ì œí’ˆë³„ íƒœê·¸ ìƒì„±"""
    tags = ["K-Beauty"]
    name = product_name.lower()
    
    # 1. ì„±ë¶„ ë° ê¸°ëŠ¥ ê¸°ë°˜ íƒœê·¸ (Ingredients & Function)
    keyword_map = {
        "Soothing": ["ì§„ì •", "ì‹œì¹´", "í‹°íŠ¸ë¦¬", "ì–´ì„±ì´ˆ", "íŒí…Œë†€", "cica", "soothing", "tea tree", "heartleaf"],
        "Hydration": ["ìˆ˜ë¶„", "ë³´ìŠµ", "íˆì•Œë£¨ë¡ ì‚°", "ë‹¤ì´ë¸Œì¸", "moisturizing", "hydrating", "hyaluronic"],
        "Brightening": ["ë¹„íƒ€", "ì²­ê·¤", "ë¯¸ë°±", "ë‚˜ì´ì•„ì‹ ", "vitamin", "brightening", "whitening", "niacinamide"],
        "Anti-aging": ["íƒ„ë ¥", "ë¦¬í”„íŒ…", "ë ˆí‹°ë†€", "pdrn", "ì½œë¼ê²", "firming", "anti-aging", "retinol", "collagen"],
        "Pore Care": ["ëª¨ê³µ", "ì œë¡œ", "pore", "tightening"],
        "Sensitive Skin": ["ë¯¼ê°", "ì €ìê·¹", "sensitive", "hypoallergenic"],
        "Glow": ["ê´‘ì±„", "ì†ê´‘", "ê¸€ë¡œìš°", "glow", "radiance"]
    }
    
    for tag, keywords in keyword_map.items():
        if any(kw in name for kw in keywords):
            tags.append(tag)
            
    # 2. ì œí˜• ë° íƒ€ì… ê¸°ë°˜ íƒœê·¸ (Form & Type)
    type_map = {
        "Serum/Ampoule": ["ì„¸ëŸ¼", "ì•°í”Œ", "serum", "ampoule"],
        "Cream": ["í¬ë¦¼", "cream"],
        "Toner/Pad": ["í† ë„ˆ", "íŒ¨ë“œ", "toner", "pad"],
        "Mask": ["ë§ˆìŠ¤í¬", "íŒ©", "mask", "pack"],
        "Sun Care": ["ì„ ", "ì¬", "uv", "sun"],
        "Cleansing": ["í´ë Œì§•", "í¼", "ì˜¤ì¼", "ë°¤", "cleansing", "foam", "oil", "balm"],
        "Mist": ["ë¯¸ìŠ¤íŠ¸", "mist"],
        "Lip Care": ["ë¦½", "í‹´íŠ¸", "ê¸€ë¡œìŠ¤", "lip", "tint", "gloss"],
        "Cushion": ["ì¿ ì…˜", "cushion"],
        "Treatment/Shampoo": ["ìƒ´í‘¸", "íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸", "shampoo", "treatment"]
    }
    
    for tag, keywords in type_map.items():
        if any(kw in name for kw in keywords):
            tags.append(tag)
            
    # 3. ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ í•„ìˆ˜ íƒœê·¸
    if category_key == "all":
        tags.append("Bestseller")
    elif category_key == "suncare":
        tags.append("UV Protection")
    elif category_key == "haircare":
        tags.append("Hair Repair")
    elif category_key == "bodycare":
        tags.append("Body Nourishment")
        
    # ì¤‘ë³µ ì œê±° ë° "Trending" ì¶”ê°€ (ëª¨ë“  ì œí’ˆ)
    tags.append("Trending")
    return list(set(tags))

async def enrich_editorial_data(model, category_key: str, products_raw: List[Dict[str, Any]], previous_rank_map: Dict[str, int] = None) -> List[Dict[str, Any]]:
    """ì œí’ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ê³µí•˜ê³  Geminië¡œ ê°•í™” (íŠ¸ë Œë“œ ê³„ì‚° ë° ê¸°ë³¸ íƒœê·¸ í¬í•¨)"""
    processed_products = []
    
    # 1. ê¸°ë³¸ êµ¬ì¡° ìƒì„±
    for idx, item in enumerate(products_raw, 1):
        raw_name = item['name']
        price_val = str(item.get('price', 'N/A'))
        image_url = item.get('url', '')
        
        brand_ko, name_ko = parse_brand_and_product(raw_name)
        
        # ë¸Œëœë“œëª… ë³€í™˜
        brand_en = BRAND_NAME_MAPPING.get(brand_ko, auto_romanize_korean(brand_ko))
        
        # íŠ¸ë Œë“œ ê³„ì‚° (v2.3 ëŒ€ë¹„)
        trend = 0
        product_key = f"{brand_ko}_{name_ko}".replace(" ", "")
        if previous_rank_map and product_key in previous_rank_map:
            prev_rank = previous_rank_map[product_key]
            trend = prev_rank - item.get('rank', idx)
            
        product = {
            'rank': item.get('rank', idx),
            'brand': brand_en,
            'brandKo': brand_ko,
            'productName': name_ko,
            'productNameKo': name_ko,
            'original_raw': raw_name,
            'tags': generate_default_tags(category_key, raw_name),
            'subcategory': category_key,
            'trend': trend,
            'price': price_val,
            'imageUrl': image_url,
            'fixedImageUrl': image_url # JSONì—ì„œ ì˜¨ ì´ë¯¸ì§€ë¥¼ ë³´ì¡´í•˜ê¸° ìœ„í•´ ë³„ë„ í•„ë“œ ì €ì¥
        }
        processed_products.append(product)

    # 2. Gemini ì¼ê´„ ë²ˆì—­ ë° ì¸ë±ì‹±/ì¸ì‚¬ì´íŠ¸ ìƒì„± (ì˜ë¬¸ í’ˆì§ˆ ê°•í™”)
    print(f"ğŸŒ Gemini AIë¡œ '{category_key}' ë¶€ë¬¸ ë°ì´í„° ê°•í™” ì¤‘ (Professional English Translation)...")
    
    product_names = [f"{p['rank']}. {p['brandKo']} {p['productNameKo']}" for p in processed_products]
    
    # ì˜ë¬¸ í’ˆì§ˆ ê°•í™”ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìˆ˜ì •
    prompt = f"""
Translate the following Korean beauty product names into professional, worldwide-recognized English.
Crucial: For Suncare, use 'Sunscreen', 'Sun Serum', or 'Sun Stick'. For Skincare, use 'Serum', 'Ampoule', or 'Toner'.

Response Requirements:
1. "productName": Clean, formal English product name. (e.g., 'Birch Juice Moisturizing Sunscreen')
2. "nikIndex": Popularity score (90.0-99.9).
3. "culturalContext": "AI Analyst Note: [Detailed insight in English]". 
   Include why it's a 'Must-buy' in Korea and mention Hwahae/Glowpick rankings.
4. "imageQuery": Best English search term for Amazon.

Product Names:
{chr(10).join(product_names)}

Response format (JSON only):
{{
  "translations": [
    {{
      "rank": 1, 
      "productName": "English Name", 
      "nikIndex": 99.1, 
      "culturalContext": "AI Analyst Note: ...",
      "imageQuery": "Brand Product Name"
    }},
    ...
  ]
}}
"""
    
    try:
        response = model.generate_content(prompt)
        result_text = response.text.strip()
        
        # JSON íŒŒì‹±
        if result_text.startswith('```'):
            result_text = result_text.split('```')[1]
            if result_text.startswith('json'):
                result_text = result_text[4:]
        
        translations = json.loads(result_text)
        
        if translations and "translations" in translations:
            for entry in translations["translations"]:
                rank = entry.get('rank')
                for p in processed_products:
                    if p['rank'] == rank:
                        p['productName'] = entry.get('productName', p['productName'])
                        p['nikIndex'] = entry.get('nikIndex', 95.0)
                        p['culturalContext'] = entry.get('culturalContext', "")
                        p['imageQuery'] = entry.get('imageQuery', f"{p['brand']} {p['productName']}")
                        # v2.3: ê¸°ì¡´ì— ì„¤ì •ëœ imageUrl(JSONì—ì„œ ì˜´)ì´ ìˆìœ¼ë©´ ìœ ì§€
                        # (entryì— imageUrlì´ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë®ì–´ì“°ì§€ ì•Šë„ë¡ ì£¼ì˜)
                        
                        # Amazon URL
                        image_query = p['imageQuery']
                        p['buyUrl'] = f"https://www.amazon.com/s?k={image_query.replace(' ', '+')}&tag={os.getenv('NEXT_PUBLIC_AMAZON_AFFILIATE_ID', 'nextidealab-20')}"
                        break
    except Exception as e:
        print(f"âš ï¸ Gemini ê°•í™” ì˜¤ë¥˜ ({category_key}): {e}")

    # 3. ì´ë¯¸ì§€ ì—°ë™ í™•ì¸ (Amazon)
    print(f"ğŸ“¸ '{category_key}' ì´ë¯¸ì§€ ë° ë§í¬ ìµœì¢… í™•ì¸ ì¤‘...")
    for p in processed_products:
        # JSON ì œê³µ ì´ë¯¸ì§€ (v2.4 ìˆ˜ë™ ì—…ë°ì´íŠ¸ëœ ê³ í’ˆì§ˆ ì´ë¯¸ì§€)ê°€ ìˆìœ¼ë©´ ìµœìš°ì„  ì‚¬ìš©
        target_img = p.get('fixedImageUrl')
        
        # JSON ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ìœ íš¨ì„± ì²´í¬ ì—†ì´ ì¦‰ì‹œ ì‚¬ìš©
        if target_img:
            # print(f"  âœ¨ Curated ì´ë¯¸ì§€ ì‚¬ìš©: {p['original_raw']}")
            pass
        else:
            # ë¬´íš¨í•˜ê±°ë‚˜ ì—†ìœ¼ë©´ Amazon ê²€ìƒ‰
            search_query = p.get('imageQuery', f"{p['brand']} {p['productName']}")
            amazon_img = await get_amazon_image(search_query)
            if amazon_img:
                target_img = amazon_img
        
        # ì—¬ì „íˆ ì—†ìœ¼ë©´ Unsplash ê³ ìœ  ì´ë¯¸ì§€ (ê²€ìƒ‰ì–´ ê¸°ë°˜)
        if not target_img:
            search_term = p.get('productNameKo', p['productName']).split(' ')[-1]
            unique_id = f"{p['brandKo']}_{p['rank']}".replace(" ", "")
            target_img = f"https://images.unsplash.com/photo-1596462502278-27bfdc4033c8?auto=format&fit=crop&q=80&w=400&sig={unique_id}&beauty={search_term}"
            
        p['imageUrl'] = target_img
        if 'fixedImageUrl' in p:
            del p['fixedImageUrl']

    return processed_products

async def main():
    print("ğŸš€ ì—ë””í† ë¦¬ì–¼ ë­í‚¹ ì„í¬íŠ¸ ì‹œì‘")
    
    # 1. ë°ì´í„° ë¡œë“œ
    if not os.path.exists(DATA_FILE):
        print(f"âŒ ë°ì´í„° íŒŒì¼ ì—†ìŒ: {DATA_FILE}")
        return
        
    with open(DATA_FILE, 'r', encoding='utf-8') as f:
        master_data = json.load(f)
        
    # 2. ì´ˆê¸°í™”
    db = initialize_firebase()
    model = initialize_gemini()
    
    today = datetime.now(timezone.utc).strftime('%Y-%m-%d')
    total_count = 0
    
    # 2.5 ì´ì „ ë²„ì „ ë°ì´í„° ë¡œë“œ (íŠ¸ë Œë“œìš©)
    prev_master_rank_map = {}
    if os.path.exists(PREVIOUS_DATA_FILE):
        print(f"ğŸ“ˆ íŠ¸ë Œë“œ ë¶„ì„ì„ ìœ„í•´ ì´ì „ ë²„ì „ ë¡œë“œ: {PREVIOUS_DATA_FILE}")
        with open(PREVIOUS_DATA_FILE, 'r', encoding='utf-8') as f:
            prev_data = json.load(f)
            for p_cat, p_items in prev_data.get('categories', {}).items():
                cat_map = {}
                for p_item in p_items:
                    p_brand_ko, p_name_ko = parse_brand_and_product(p_item['name'])
                    p_key = f"{p_brand_ko}_{p_name_ko}".replace(" ", "")
                    cat_map[p_key] = p_item['rank']
                prev_master_rank_map[p_cat] = cat_map
    
    # 3. ì¹´í…Œê³ ë¦¬ë³„ ì²˜ë¦¬
    for cat_key, products_raw in master_data['categories'].items():
        print(f"\nğŸ“‚ ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ ì¤‘: {cat_key.upper()} ({len(products_raw)} items)")
        
        # íŠ¸ë Œë“œ ë§µ ê°€ì ¸ì˜¤ê¸°
        prev_rank_map = prev_master_rank_map.get(cat_key)
        
        # ë°ì´í„° ê°•í™”
        enriched_products = await enrich_editorial_data(model, cat_key, products_raw, prev_rank_map)
        
        # Firestore ì €ì¥
        firestore_category = CATEGORY_MAPPING.get(cat_key, {'firestore_category': cat_key})['firestore_category']
        doc_id = f"{today}_{firestore_category}"
        
        data = {
            'date': today,
            'category': firestore_category,
            'items': enriched_products,
            'updatedAt': firestore.SERVER_TIMESTAMP,
            'isEditorial': True,
            'reportTitle': "NIK Beauty Index: Weekly Editorial Report (v2.4)"
        }
        
        if WRITE_TO_FIRESTORE:
            db.collection('daily_rankings').document(doc_id).set(data)
            print(f"âœ… Firestore ì €ì¥ ì™„ë£Œ: {doc_id}")
        else:
            print(f"ğŸ§ª [DEV_MODE] Firestore ì €ì¥ ìŠ¤í‚µ: {doc_id}")
            if enriched_products:
                print(f"ğŸ” DEBUG [Item 0]: {json.dumps(enriched_products[0], indent=2, ensure_ascii=False)}")
            
        total_count += len(enriched_products)
        
    print(f"\nâœ¨ ì™„ë£Œ! ì´ {total_count}ê°œ ì œí’ˆì´ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    asyncio.run(main())
